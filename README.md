# ğŸŒ **Earthquake Data Pipeline - Databricks & Azure Data Lake** âš¡

<img width="962" alt="image" src="https://github.com/user-attachments/assets/3572d185-d1aa-4304-92c1-900c22ad9908" />


## ğŸ“Œ VisÃ£o Geral

Este repositÃ³rio contÃ©m uma **pipeline de dados distribuÃ­da e escalÃ¡vel** construÃ­da no **Azure Databricks**, projetada para coletar, transformar e organizar dados sÃ­smicos da **USGS Earthquake API**.

A soluÃ§Ã£o segue o modelo **Medallion Architecture** (**Bronze, Silver e Gold**), permitindo ingestÃ£o eficiente, tratamento de dados e armazenamento estruturado para anÃ¡lise avanÃ§ada.

O pipeline Ã© **totalmente orquestrado dentro do Databricks**, sem necessidade de ferramentas externas como **Data Factory** ou **Synapse Analytics**.

---

## ğŸ  Arquitetura da Pipeline

A execuÃ§Ã£o do fluxo de dados Ã© gerenciada por um **workflow no Databricks**, que segue a seguinte sequÃªncia:

### ğŸ”¹ **Uma Abordagem Moderna: Tudo no Databricks**

Esta pipeline adota uma **abordagem moderna baseada inteiramente no Databricks**, dispensando ferramentas externas como **Azure Data Factory e Synapse Analytics**. Essa estratÃ©gia se alinha com a tendÃªncia atual do mercado, onde muitas empresas estÃ£o migrando para um modelo **Lakehouse**.

âœ… **GovernanÃ§a centralizada** â†’ Uso de **IAM e External Locations** para controle seguro dos dados.  
âœ… **Menos dependÃªncias** â†’ Tudo Ã© gerenciado dentro do **Databricks**, reduzindo a necessidade de integraÃ§Ãµes externas.  
âœ… **Melhor performance** â†’ A utilizaÃ§Ã£o do **Delta Lake e Parquet** garante **baixo custo e alta eficiÃªncia**.  
âœ… **Flexibilidade** â†’ Permite **ajustes rÃ¡pidos** e mais controle sobre a orquestraÃ§Ã£o sem precisar de pipelines separados no ADF.  
âœ… **Custo otimizado** â†’ ReduÃ§Ã£o de custos ao evitar execuÃ§Ã£o desnecessÃ¡ria de pipelines no Azure Data Factory.

---

### ğŸ”¹ **Origem dos Dados (Azure External Locations)**

- Os dados sÃ£o extraÃ­dos a partir da funcionalidade **Dados Externos** no Databricks.
- Diferente da abordagem tradicional com **Azure Data Factory**, utilizamos **credenciais gerenciadas** no prÃ³prio Databricks.
- A credencial foi criada e configurada para acessar **containers especÃ­ficos no Azure Data Lake**, garantindo controle granular de permissÃµes.
- As localizaÃ§Ãµes externas foram configuradas para as camadas **Bronze, Silver e Gold**, permitindo que os dados sejam acessados diretamente no Databricks sem necessidade de cÃ³pias adicionais.

### ğŸ”¹ **Controle de Acesso via IAM**

- O acesso ao **Azure Data Lake** foi configurado via **IAM (Identity and Access Management)** no Azure.
- A identidade gerenciada `unity-catalog-access-connector` foi adicionada como **Colaboradora de Dados do Storage Blob**, garantindo que os notebooks e workflows no Databricks possam acessar os containers do Data Lake de forma segura.
- Esse mÃ©todo reduz a necessidade de armazenar credenciais dentro do cÃ³digo e melhora a governanÃ§a dos dados.

### ğŸ”¹ **Bibliotecas Externas Utilizadas**

- Durante a execuÃ§Ã£o do pipeline, foi necessÃ¡ria a instalaÃ§Ã£o da biblioteca **`reverse_geocoder`** diretamente no **cluster do Databricks**.
- A instalaÃ§Ã£o foi feita via **PyPI**, garantindo suporte a funcionalidades de geocodificaÃ§Ã£o reversa utilizadas no processamento dos dados sÃ­smicos.
- Exemplo de instalaÃ§Ã£o manual:
  ```python
  %pip install reverse_geocoder
  ```
  Ou, via interface do Databricks:
  - Navegue atÃ© o cluster e vÃ¡ para a aba **Bibliotecas**.
  - Clique em **Instalar novo** e selecione **PyPI**.
  - Digite `reverse_geocoder` e clique em **Instalar**.

### ğŸ”¸ **Bronze Layer (IngestÃ£o de Dados Brutos)**

- **ConexÃ£o com a API**: A API da **USGS Earthquake** Ã© acessada utilizando o mÃ©todo `GET` do mÃ³dulo `requests`, permitindo a obtenÃ§Ã£o de dados sÃ­smicos em tempo real.
- **ParÃ¢metros Configurados**: A data inicial e final sÃ£o definidas dinamicamente e passadas como query parameters.
- **Leitura e ConversÃ£o de Dados**: O retorno da API (JSON) Ã© convertido para um **DataFrame PySpark** para manipulaÃ§Ã£o eficiente.
- **Armazenamento no Azure Data Lake**: Os dados sÃ£o salvos no formato **Parquet**, garantindo eficiÃªncia e compatibilidade com as prÃ³ximas camadas.
- **DefiniÃ§Ã£o de VariÃ¡veis para PrÃ³ximas Etapas**:
  ```python
  start_date = "2025-02-10"
  bronze_adls = "abfss://bronze@yourdatalake.dfs.core.windows.net/earthquake_data"
  silver_adls = "abfss://silver@yourdatalake.dfs.core.windows.net/earthquake_data"
  dbutils.jobs.taskValues.set(
      key="bronze_output",
      value={"start_date": start_date, "bronze_adls": bronze_adls, "silver_adls": silver_adls}
  )
  ```

### ğŸ”¸ **Silver Layer (TransformaÃ§Ã£o e Enriquecimento)**

- **RecuperaÃ§Ã£o dos valores da Bronze Layer**:
  ```python
  bronze_output = dbutils.jobs.taskValues.get(
      taskKey="Bronze",
      key="bronze_output"
  )
  start_date = bronze_output.get("start_date", "")
  bronze_adls = bronze_output.get("bronze_adls", "")
  silver_adls = bronze_output.get("silver_adls", "")
  ```
- **NormalizaÃ§Ã£o dos dados**, aplicando ajustes estruturais e padronizaÃ§Ãµes.
- **Enriquecimento das informaÃ§Ãµes**, incluindo junÃ§Ãµes e manipulaÃ§Ãµes adicionais.
- **CriaÃ§Ã£o de colunas estruturadas** para facilitar anÃ¡lises futuras.
- **Escrita dos dados na camada Silver** dentro do **Azure Data Lake**.

### ğŸ† **Gold Layer (Dados Prontos para Consumo)**

- **RecuperaÃ§Ã£o dos valores da Silver Layer**:
  ```python
  silver_output = dbutils.jobs.taskValues.get(
      taskKey="Silver",
      key="silver_output"
  )
  ```
- AgregaÃ§Ã£o de dados e cÃ¡lculos estatÃ­sticos relevantes.
- ConversÃ£o dos dados para um formato otimizado para consultas.
- ExportaÃ§Ã£o dos dados refinados para a camada **Gold** no **Azure Data Lake**.

---

## ğŸš€ BenefÃ­cios da SoluÃ§Ã£o

âœ”ï¸ **AutomatizaÃ§Ã£o Completa** â†’ Fluxo 100% gerenciado dentro do Databricks.  
âœ”ï¸ **Escalabilidade** â†’ Capacidade de processar grandes volumes de dados sÃ­smicos.  
âœ”ï¸ **EficiÃªncia e OrganizaÃ§Ã£o** â†’ Dados estruturados em camadas para fÃ¡cil consumo.  
âœ”ï¸ **Alto Desempenho** â†’ Uso otimizado do Apache Spark para processamento distribuÃ­do.  
âœ”ï¸ **SeguranÃ§a Aprimorada** â†’ Uso de IAM e External Locations para controle de acesso seguro.

---

## ğŸ’¡ ContribuiÃ§Ãµes

Sinta-se Ã  vontade para sugerir melhorias, abrir issues ou contribuir para otimizar a pipeline!

ğŸ“© Para dÃºvidas ou sugestÃµes, entre em contato.

